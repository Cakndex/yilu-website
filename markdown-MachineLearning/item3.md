# 三、论文阅读🙌

> 提到ai便离不开gpt，文心一言等大模型，他们的主要原理是什么呢？什么是注意力机制呢？

1. （大一的同学）阅读论文《Attention is all you need》，尝试完成模型代码，提交代码和论文理解（论文理解按照链接里面的模板写。）
  
   一些提示：

2. Transformer主要包括哪几个结构？

3. Transformer大致的原理是什么？

4. Transformer在现实生活的应用有哪些？

5. （大二的同学）阅读论文《Location Predict for tweet》，尝试完成模型代码，提交代码和论文理解。
  
6. （论文理解按照链接里面的模板写。）

7. 一些提示：

8. 结合RNN和CNN的优点是什么？他们各自有什么缺点呢？RNN和LTSM有什么区别？RNN还有哪些变体呢？

9. 什么是多头注意力机制？它是怎么工作的？

> 论文链接：<https://pan.baidu.com/s/1AHayldqriI3mZsDIT4Yg-A>
>
> 提取码：yilu

1. 论文理解文件命名格式：“年级+论文名+姓名”，提交 pdf 文件。
2. 代码文件命名格式：“年级+姓名+自定义代码文件名”，提交.py 文件
